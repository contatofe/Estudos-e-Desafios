{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPiJURffXhm9oryoIyp9c3y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/contatofe/Estudos-e-Desafios/blob/main/Vis%C3%A3o%20Computacional%20-%20IA%20Expert/Reconhecimento%20de%20gestos%20-%20IA%20Expert/Reconhecimento_de_gestos_AI_Expert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zZUasReaasZd"
      },
      "outputs": [],
      "source": [
        "# Importações\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montando o drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvvHwrQgbPrk",
        "outputId": "29788a0a-9368-40ed-8ccd-9d8897ae8c4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando a rede neural pré treinada\n",
        "\n",
        "network = cv2.dnn.readNetFromCaffe('/content/drive/MyDrive/Arquivos - Dados/Curso - visão computacional/Weights/pose_deploy_linevec_faster_4_stages.prototxt',\n",
        "                                   '/content/drive/MyDrive/Arquivos - Dados/Curso - visão computacional/Weights/pose_iter_160000.caffemodel')"
      ],
      "metadata": {
        "id": "VKx43ijWbUKK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsão de pontos corporais\n",
        "\n",
        "video = '/content/drive/MyDrive/Arquivos - Dados/Curso - visão computacional/Videos/gesture1.mp4'\n",
        "captura = cv2.VideoCapture(video)\n",
        "conected, frame = captura.read()\n",
        "print(conected, frame.shape)\n",
        "\n",
        "connection_points = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1, 14],\n",
        "                  [14,8], [8,9], [9,10], [14,11], [11,12],[12,13]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO3K4VgYbiV_",
        "outputId": "27adde29-902d-4b3d-b841-ef7719be7d36"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True (1080, 808, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Funções\n",
        "\n",
        "def check_arms(points):\n",
        "\n",
        "  head, right_hand, left_hand = 0, 0, 0\n",
        "\n",
        "  for i, point in enumerate(points):\n",
        "    if i == 0:\n",
        "      head = point[1]\n",
        "    elif i == 4:\n",
        "      right_hand = point[1]\n",
        "    elif i == 7:\n",
        "      left_hand = point[1]\n",
        "\n",
        "  if right_hand < head and left_hand < head:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def check_legs(points):\n",
        "  left_hip, right_hip = 0, 0\n",
        "  left_foot, right_foot = 0, 0\n",
        "\n",
        "  for i, point in enumerate(points):\n",
        "    if i == 11:\n",
        "      left_hip = point[0]\n",
        "    elif i == 8:\n",
        "      right_hip = point[0]\n",
        "    elif i == 13:\n",
        "      left_foot = point[0]\n",
        "    elif i == 10:\n",
        "      right_foot = point[0]\n",
        "\n",
        "  if (left_foot > left_hip) and (right_foot < right_hip):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "metadata": {
        "id": "xLYgntJDe8SK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsão de gestos\n",
        "\n",
        "results = '/content/gesture1_result.mp4'\n",
        "save_video = cv2.VideoWriter(results, cv2.VideoWriter_fourcc(*'XVID'), 10, (frame.shape[1], frame.shape[0]))\n",
        "\n",
        "threshold = 0.1\n",
        "while cv2.waitKey(1) < 0:\n",
        "  conected, frame = captura.read()\n",
        "\n",
        "  if not conected:\n",
        "    break\n",
        "\n",
        "  img_blob = cv2.dnn.blobFromImage(image = frame, scalefactor = 1.0 / 255, size = (256, 256))\n",
        "  network.setInput(img_blob)\n",
        "  output = network.forward()\n",
        "\n",
        "  width_position = output.shape[2]\n",
        "  height_position = output.shape[3]\n",
        "\n",
        "  point_number = 15\n",
        "  points = []\n",
        "\n",
        "  for i in range(point_number):\n",
        "    confience_map = output[0, i, :, :]\n",
        "    _, confidence, _, point = cv2.minMaxLoc(confience_map)\n",
        "    x = int((frame.shape[1] * point[0]) / width_position)\n",
        "    y = int((frame.shape[0] * point[1]) / height_position)\n",
        "\n",
        "    if confidence > threshold:\n",
        "      cv2.circle(frame, (x, y), 5, (0,255,0), thickness = -1)\n",
        "      cv2.putText(frame, \"{}\".format(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, .7, (0, 0, 255))\n",
        "      points.append((x, y))\n",
        "    else:\n",
        "      points.append(None)\n",
        "\n",
        "  for connection in connection_points:\n",
        "    parteA = connection[0]\n",
        "    parteB = connection[1]\n",
        "    if points[parteA] and points[parteB]:\n",
        "      cv2.line(frame, points[parteA], points[parteB], (255,0,0))\n",
        "\n",
        "  if check_arms(points) == True and check_legs(points) == True:\n",
        "    cv2.putText(frame, 'Completo', (50,200), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0))\n",
        "\n",
        "  save_video.write(frame)\n",
        "save_video.release()\n",
        "print('Processamento concluído!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6KxVi1ob7xZ",
        "outputId": "ddf27938-0de8-45a4-bdfc-8087fb8bb5ca"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processamento concluído!\n"
          ]
        }
      ]
    }
  ]
}